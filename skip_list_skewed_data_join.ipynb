{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895f00c1-0739-484e-b64d-76a2b9ca146b",
   "metadata": {},
   "source": [
    "### Skip List Join w/ Skewed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25870ae0-50ab-4870-9e15-2bd954857d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Small Dataset Test ===\n",
      "Skip list build time: 0.001834 seconds\n",
      "Skip list join time: 0.001843 seconds\n",
      "Total skip list join time: 0.003677 seconds\n",
      "Hash table build time: 0.000106 seconds\n",
      "Hash join time: 0.000483 seconds\n",
      "Total hash join time: 0.000589 seconds\n",
      "Pandas join time: 0.021457 seconds\n",
      "Skip list join result size: 1982\n",
      "Hash join result size: 1982\n",
      "Pandas join result size: 1982\n",
      "Nested loop join time: 0.000356 seconds\n",
      "Nested loop join result size (on 100x100 subset): 27\n",
      "\n",
      "=== Medium Dataset Test ===\n",
      "Skip list build time: 0.023480 seconds\n",
      "Skip list join time: 0.051116 seconds\n",
      "Total skip list join time: 0.074596 seconds\n",
      "Hash table build time: 0.001619 seconds\n",
      "Hash join time: 0.005374 seconds\n",
      "Total hash join time: 0.006993 seconds\n",
      "Pandas join time: 0.042420 seconds\n",
      "Skip list join result size: 20346\n",
      "Hash join result size: 20346\n",
      "Pandas join result size: 20346\n",
      "\n",
      "=== Large Dataset Test ===\n",
      "Skip list build time: 0.379243 seconds\n",
      "Skip list join time: 0.539289 seconds\n",
      "Total skip list join time: 0.918532 seconds\n",
      "Hash table build time: 0.016851 seconds\n",
      "Hash join time: 0.110037 seconds\n",
      "Total hash join time: 0.126888 seconds\n",
      "Pandas join time: 0.417514 seconds\n",
      "Skip list join result size: 199097\n",
      "Hash join result size: 199097\n",
      "Pandas join result size: 199097\n",
      "\n",
      "=== Skewed Data Distribution Test ===\n",
      "Skip list build time: 0.076466 seconds\n",
      "Skip list join time: 7.584964 seconds\n",
      "Total skip list join time: 7.661430 seconds\n",
      "Hash table build time: 0.004802 seconds\n",
      "Hash join time: 11.498558 seconds\n",
      "Total hash join time: 11.503361 seconds\n",
      "Pandas join time: 35.727267 seconds\n",
      "Skip list join result size: 20250113\n",
      "Hash join result size: 20250113\n",
      "Pandas join result size: 20250113\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Any, Optional\n",
    "\n",
    "\n",
    "class SkipNode:\n",
    "    \"\"\"A node in the Skip List\"\"\"\n",
    "    \n",
    "    def __init__(self, key: Any, value: Any, level: int):\n",
    "        self.key = key\n",
    "        self.value = value  # Could be a list of values if there are duplicates\n",
    "        self.forward = [None] * (level + 1)  # Array of pointers for each level\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"SkipNode(key={self.key}, value={self.value})\"\n",
    "\n",
    "\n",
    "class SkipList:\n",
    "    \"\"\"Skip list implementation with search, insert, and delete operations\"\"\"\n",
    "    \n",
    "    def __init__(self, max_level: int = 16, p: float = 0.5):\n",
    "        self.max_level = max_level  # Maximum level of the skip list\n",
    "        self.p = p  # Probability of promoting to next level\n",
    "        self.level = 0  # Current maximum level of skip list\n",
    "        \n",
    "        # Create head node with key set to None (will be smaller than all real keys)\n",
    "        self.head = SkipNode(None, None, max_level)\n",
    "    \n",
    "    def random_level(self) -> int:\n",
    "        \"\"\"Randomly determine the level for a new node\"\"\"\n",
    "        level = 0\n",
    "        while random.random() < self.p and level < self.max_level:\n",
    "            level += 1\n",
    "        return level\n",
    "    \n",
    "    def search(self, key: Any) -> Optional[Any]:\n",
    "        \"\"\"Search for a key in the skip list\"\"\"\n",
    "        current = self.head\n",
    "        \n",
    "        # Start from the highest level and work down\n",
    "        for i in range(self.level, -1, -1):\n",
    "            # Move forward at the current level as far as possible\n",
    "            while current.forward[i] and current.forward[i].key < key:\n",
    "                current = current.forward[i]\n",
    "        \n",
    "        # Move to the node right after the last smaller key\n",
    "        current = current.forward[0]\n",
    "        \n",
    "        # Return the value if the key matches, otherwise None\n",
    "        if current and current.key == key:\n",
    "            return current.value\n",
    "        return None\n",
    "    \n",
    "    def search_range(self, start_key: Any, end_key: Any) -> List[Tuple[Any, Any]]:\n",
    "        \"\"\"Search for keys in the given range (inclusive)\"\"\"\n",
    "        result = []\n",
    "        \n",
    "        # Find the first node greater than or equal to start_key\n",
    "        current = self.head\n",
    "        for i in range(self.level, -1, -1):\n",
    "            while current.forward[i] and current.forward[i].key < start_key:\n",
    "                current = current.forward[i]\n",
    "        \n",
    "        # Move to the first node in range\n",
    "        current = current.forward[0]\n",
    "        \n",
    "        # Collect all nodes in range\n",
    "        while current and current.key <= end_key:\n",
    "            result.append((current.key, current.value))\n",
    "            current = current.forward[0]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def insert(self, key: Any, value: Any):\n",
    "        \"\"\"Insert a new key-value pair into the skip list\"\"\"\n",
    "        # Array to track updates at each level\n",
    "        update = [None] * (self.max_level + 1)\n",
    "        current = self.head\n",
    "        \n",
    "        # Find the position to insert the new node\n",
    "        for i in range(self.level, -1, -1):\n",
    "            while current.forward[i] and current.forward[i].key < key:\n",
    "                current = current.forward[i]\n",
    "            update[i] = current\n",
    "        \n",
    "        # Move to the next node\n",
    "        current = current.forward[0]\n",
    "        \n",
    "        # If key already exists, update the value\n",
    "        if current and current.key == key:\n",
    "            if isinstance(current.value, list):\n",
    "                current.value.append(value)\n",
    "            else:\n",
    "                current.value = [current.value, value]\n",
    "            return\n",
    "        \n",
    "        # Generate a random level for the new node\n",
    "        new_level = self.random_level()\n",
    "        \n",
    "        # Update the skip list's level if the new level is higher\n",
    "        if new_level > self.level:\n",
    "            for i in range(self.level + 1, new_level + 1):\n",
    "                update[i] = self.head\n",
    "            self.level = new_level\n",
    "        \n",
    "        # Create a new node\n",
    "        new_node = SkipNode(key, value, new_level)\n",
    "        \n",
    "        # Insert the new node by updating the forward links\n",
    "        for i in range(new_level + 1):\n",
    "            new_node.forward[i] = update[i].forward[i]\n",
    "            update[i].forward[i] = new_node\n",
    "    \n",
    "    def delete(self, key: Any):\n",
    "        \"\"\"Delete a key from the skip list\"\"\"\n",
    "        update = [None] * (self.max_level + 1)\n",
    "        current = self.head\n",
    "        \n",
    "        # Find the position of the node to delete\n",
    "        for i in range(self.level, -1, -1):\n",
    "            while current.forward[i] and current.forward[i].key < key:\n",
    "                current = current.forward[i]\n",
    "            update[i] = current\n",
    "        \n",
    "        # Move to the node to delete\n",
    "        current = current.forward[0]\n",
    "        \n",
    "        # If the key exists, update the forward links to skip it\n",
    "        if current and current.key == key:\n",
    "            for i in range(self.level + 1):\n",
    "                if update[i].forward[i] != current:\n",
    "                    break\n",
    "                update[i].forward[i] = current.forward[i]\n",
    "            \n",
    "            # Update the skip list's level if needed\n",
    "            while self.level > 0 and self.head.forward[self.level] is None:\n",
    "                self.level -= 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate through all nodes in the skip list\"\"\"\n",
    "        current = self.head.forward[0]\n",
    "        while current:\n",
    "            yield (current.key, current.value)\n",
    "            current = current.forward[0]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"String representation of the skip list\"\"\"\n",
    "        elements = list(self)\n",
    "        return f\"SkipList({elements})\"\n",
    "\n",
    "\n",
    "def skip_list_join(left_data: List[Dict], right_data: List[Dict], \n",
    "                   left_key: str, right_key: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform an inner join using a skip list to index the right table\n",
    "    \"\"\"\n",
    "    # Build a skip list index on the right table\n",
    "    skip_list = SkipList()\n",
    "    start_build = time.time()\n",
    "    \n",
    "    for record in right_data:\n",
    "        key = record[right_key]\n",
    "        skip_list.insert(key, record)\n",
    "    \n",
    "    build_time = time.time() - start_build\n",
    "    print(f\"Skip list build time: {build_time:.6f} seconds\")\n",
    "    \n",
    "    # Perform the join by searching the skip list for each record in the left table\n",
    "    start_join = time.time()\n",
    "    result = []\n",
    "    \n",
    "    for left_record in left_data:\n",
    "        left_val = left_record[left_key]\n",
    "        right_records = skip_list.search(left_val)\n",
    "        \n",
    "        if right_records:\n",
    "            # Handle case where we have multiple matches\n",
    "            if isinstance(right_records, list):\n",
    "                for right_record in right_records:\n",
    "                    joined_record = {**left_record, **right_record}\n",
    "                    result.append(joined_record)\n",
    "            else:\n",
    "                joined_record = {**left_record, **right_records}\n",
    "                result.append(joined_record)\n",
    "    \n",
    "    join_time = time.time() - start_join\n",
    "    print(f\"Skip list join time: {join_time:.6f} seconds\")\n",
    "    print(f\"Total skip list join time: {build_time + join_time:.6f} seconds\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def hash_join(left_data: List[Dict], right_data: List[Dict], \n",
    "              left_key: str, right_key: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform an inner join using a hash table to index the right table\n",
    "    \"\"\"\n",
    "    # Build a hash table index on the right table\n",
    "    start_build = time.time()\n",
    "    hash_table = {}\n",
    "    \n",
    "    for record in right_data:\n",
    "        key = record[right_key]\n",
    "        if key in hash_table:\n",
    "            hash_table[key].append(record)\n",
    "        else:\n",
    "            hash_table[key] = [record]\n",
    "    \n",
    "    build_time = time.time() - start_build\n",
    "    print(f\"Hash table build time: {build_time:.6f} seconds\")\n",
    "    \n",
    "    # Perform the join by searching the hash table for each record in the left table\n",
    "    start_join = time.time()\n",
    "    result = []\n",
    "    \n",
    "    for left_record in left_data:\n",
    "        left_val = left_record[left_key]\n",
    "        if left_val in hash_table:\n",
    "            for right_record in hash_table[left_val]:\n",
    "                joined_record = {**left_record, **right_record}\n",
    "                result.append(joined_record)\n",
    "    \n",
    "    join_time = time.time() - start_join\n",
    "    print(f\"Hash join time: {join_time:.6f} seconds\")\n",
    "    print(f\"Total hash join time: {build_time + join_time:.6f} seconds\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def pandas_join(left_data: List[Dict], right_data: List[Dict], \n",
    "                left_key: str, right_key: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform an inner join using pandas\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert lists of dictionaries to pandas DataFrames\n",
    "    left_df = pd.DataFrame(left_data)\n",
    "    right_df = pd.DataFrame(right_data)\n",
    "    \n",
    "    # Perform the join\n",
    "    result_df = pd.merge(left_df, right_df, left_on=left_key, right_on=right_key)\n",
    "    \n",
    "    # Convert the result back to a list of dictionaries\n",
    "    result = result_df.to_dict('records')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Pandas join time: {end_time - start_time:.6f} seconds\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def nested_loop_join(left_data: List[Dict], right_data: List[Dict], \n",
    "                     left_key: str, right_key: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform a simple nested loop join\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    result = []\n",
    "    \n",
    "    for left_record in left_data:\n",
    "        for right_record in right_data:\n",
    "            if left_record[left_key] == right_record[right_key]:\n",
    "                joined_record = {**left_record, **right_record}\n",
    "                result.append(joined_record)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Nested loop join time: {end_time - start_time:.6f} seconds\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_test_data(size_left: int, size_right: int, \n",
    "                       key_range: int, seed: int = 42) -> Tuple[List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Generate test data for join operations\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    left_data = []\n",
    "    right_data = []\n",
    "    \n",
    "    # Generate left table\n",
    "    for i in range(size_left):\n",
    "        record = {\n",
    "            'id': i,\n",
    "            'join_key': random.randint(1, key_range),\n",
    "            'value_left': f\"left_value_{i}\"\n",
    "        }\n",
    "        left_data.append(record)\n",
    "    \n",
    "    # Generate right table\n",
    "    for i in range(size_right):\n",
    "        record = {\n",
    "            'id': i,\n",
    "            'join_key': random.randint(1, key_range),\n",
    "            'value_right': f\"right_value_{i}\"\n",
    "        }\n",
    "        right_data.append(record)\n",
    "    \n",
    "    return left_data, right_data\n",
    "\n",
    "\n",
    "def test_joins():\n",
    "    \"\"\"\n",
    "    Test different join algorithms with various data sizes and distributions\n",
    "    \"\"\"\n",
    "    print(\"=== Small Dataset Test ===\")\n",
    "    left_data, right_data = generate_test_data(1000, 1000, 500)\n",
    "    \n",
    "    # Verify all joins produce the same results\n",
    "    skip_result = skip_list_join(left_data, right_data, 'join_key', 'join_key')\n",
    "    hash_result = hash_join(left_data, right_data, 'join_key', 'join_key')\n",
    "    pandas_result = pandas_join(left_data, right_data, 'join_key', 'join_key')\n",
    "    \n",
    "    print(f\"Skip list join result size: {len(skip_result)}\")\n",
    "    print(f\"Hash join result size: {len(hash_result)}\")\n",
    "    print(f\"Pandas join result size: {len(pandas_result)}\")\n",
    "    \n",
    "    # Test nested loop join only on small dataset as it's very slow\n",
    "    nested_result = nested_loop_join(left_data[:100], right_data[:100], 'join_key', 'join_key')\n",
    "    print(f\"Nested loop join result size (on 100x100 subset): {len(nested_result)}\")\n",
    "    \n",
    "    print(\"\\n=== Medium Dataset Test ===\")\n",
    "    left_data, right_data = generate_test_data(10000, 10000, 5000)\n",
    "    \n",
    "    skip_result = skip_list_join(left_data, right_data, 'join_key', 'join_key')\n",
    "    hash_result = hash_join(left_data, right_data, 'join_key', 'join_key')\n",
    "    pandas_result = pandas_join(left_data, right_data, 'join_key', 'join_key')\n",
    "    \n",
    "    print(f\"Skip list join result size: {len(skip_result)}\")\n",
    "    print(f\"Hash join result size: {len(hash_result)}\")\n",
    "    print(f\"Pandas join result size: {len(pandas_result)}\")\n",
    "    \n",
    "    print(\"\\n=== Large Dataset Test ===\")\n",
    "    left_data, right_data = generate_test_data(100000, 100000, 50000)\n",
    "    \n",
    "    skip_result = skip_list_join(left_data, right_data, 'join_key', 'join_key')\n",
    "    hash_result = hash_join(left_data, right_data, 'join_key', 'join_key')\n",
    "    pandas_result = pandas_join(left_data, right_data, 'join_key', 'join_key')\n",
    "    \n",
    "    print(f\"Skip list join result size: {len(skip_result)}\")\n",
    "    print(f\"Hash join result size: {len(hash_result)}\")\n",
    "    print(f\"Pandas join result size: {len(pandas_result)}\")\n",
    "    \n",
    "    # Test with skewed data distribution\n",
    "    print(\"\\n=== Skewed Data Distribution Test ===\")\n",
    "    \n",
    "    # Create skewed data with 80% of keys in a small range\n",
    "    left_skewed = []\n",
    "    right_skewed = []\n",
    "    \n",
    "    for i in range(50000):\n",
    "        skewed_key = random.randint(1, 100) if random.random() < 0.9 else random.randint(101, 5000)\n",
    "        left_record = {\n",
    "            'id': i,\n",
    "            'join_key': skewed_key,\n",
    "            'value_left': f\"left_value_{i}\"\n",
    "        }\n",
    "        left_skewed.append(left_record)\n",
    "        \n",
    "        skewed_key = random.randint(1, 100) if random.random() < 0.9 else random.randint(101, 5000)\n",
    "        right_record = {\n",
    "            'id': i,\n",
    "            'join_key': skewed_key,\n",
    "            'value_right': f\"right_value_{i}\"\n",
    "        }\n",
    "        right_skewed.append(right_record)\n",
    "    \n",
    "    skip_result = skip_list_join(left_skewed, right_skewed, 'join_key', 'join_key')\n",
    "    hash_result = hash_join(left_skewed, right_skewed, 'join_key', 'join_key')\n",
    "    pandas_result = pandas_join(left_skewed, right_skewed, 'join_key', 'join_key')\n",
    "    \n",
    "    print(f\"Skip list join result size: {len(skip_result)}\")\n",
    "    print(f\"Hash join result size: {len(hash_result)}\")\n",
    "    print(f\"Pandas join result size: {len(pandas_result)}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_joins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfcb5aa-3f1b-4aba-b6aa-f28d626225b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Data Science)",
   "language": "python",
   "name": "py311ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
