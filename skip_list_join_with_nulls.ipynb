{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b50c87-4bfd-4689-8cd6-a216ea0868e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Large Dataset Test (Uniform Distribution) ===\n",
      "Skip list build time: 0.664407 seconds\n",
      "Skip list join time: 0.720558 seconds\n",
      "Total skip list join time: 1.384965 seconds\n",
      "Hash table build time: 0.050177 seconds\n",
      "Hash join time: 0.123285 seconds\n",
      "Total hash join time: 0.173462 seconds\n",
      "Pandas join time: 0.491829 seconds\n",
      "Skip list join result size: 201202\n",
      "Hash join result size: 201202\n",
      "Pandas join result size: 201202\n",
      "\n",
      "=== Large Dataset Test (Skewed Distribution) ===\n",
      "Skip list build time: 0.498172 seconds\n",
      "Skip list join time: 1.177492 seconds\n",
      "Total skip list join time: 1.675664 seconds\n",
      "Hash table build time: 0.062106 seconds\n",
      "Hash join time: 0.670021 seconds\n",
      "Total hash join time: 0.732127 seconds\n",
      "Pandas join time: 3.102796 seconds\n",
      "Skip list join result size: 1656293\n",
      "Hash join result size: 1656293\n",
      "Pandas join result size: 1656293\n",
      "\n",
      "=== Large Dataset Test (String Keys) ===\n",
      "Skip list build time: 0.964959 seconds\n",
      "Skip list join time: 0.735104 seconds\n",
      "Total skip list join time: 1.700063 seconds\n",
      "Hash table build time: 0.070915 seconds\n",
      "Hash join time: 0.010530 seconds\n",
      "Total hash join time: 0.081445 seconds\n",
      "Pandas join time: 0.146731 seconds\n",
      "Skip list join result size: 0\n",
      "Hash join result size: 0\n",
      "Pandas join result size: 0\n",
      "\n",
      "=== Large Dataset Test (Null Values) ===\n",
      "Skip list build time: 0.578096 seconds\n",
      "Skip list join time: 24.851882 seconds\n",
      "Total skip list join time: 25.429978 seconds\n",
      "Hash table build time: 0.019139 seconds\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Any, Optional\n",
    "\n",
    "\n",
    "class SkipNode:\n",
    "    \"\"\"A node in the Skip List\"\"\"\n",
    "    \n",
    "    def __init__(self, key: Any, value: Any, level: int):\n",
    "        self.key = key\n",
    "        self.value = value  # Could be a list of values if there are duplicates\n",
    "        self.forward = [None] * (level + 1)  # Array of pointers for each level\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"SkipNode(key={self.key}, value={self.value})\"\n",
    "\n",
    "\n",
    "class SkipList:\n",
    "    \"\"\"Skip list implementation with search, insert, and delete operations\"\"\"\n",
    "    \n",
    "    def __init__(self, max_level: int = 16, p: float = 0.5):\n",
    "        self.max_level = max_level\n",
    "        self.p = p\n",
    "        self.level = 0\n",
    "        self.head = SkipNode(None, None, max_level)\n",
    "    \n",
    "    def random_level(self) -> int:\n",
    "        level = 0\n",
    "        while random.random() < self.p and level < self.max_level:\n",
    "            level += 1\n",
    "        return level\n",
    "    \n",
    "    def search(self, key: Any) -> Optional[Any]:\n",
    "        current = self.head\n",
    "        for i in range(self.level, -1, -1):\n",
    "            while current.forward[i] and self._compare_keys(current.forward[i].key, key) < 0:\n",
    "                current = current.forward[i]\n",
    "        current = current.forward[0]\n",
    "        if current and self._compare_keys(current.key, key) == 0:\n",
    "            return current.value\n",
    "        return None\n",
    "    \n",
    "    def insert(self, key: Any, value: Any):\n",
    "        update = [None] * (self.max_level + 1)\n",
    "        current = self.head\n",
    "        for i in range(self.level, -1, -1):\n",
    "            while current.forward[i] and self._compare_keys(current.forward[i].key, key) < 0:\n",
    "                current = current.forward[i]\n",
    "            update[i] = current\n",
    "        current = current.forward[0]\n",
    "        if current and self._compare_keys(current.key, key) == 0:\n",
    "            if isinstance(current.value, list):\n",
    "                current.value.append(value)\n",
    "            else:\n",
    "                current.value = [current.value, value]\n",
    "            return\n",
    "        new_level = self.random_level()\n",
    "        if new_level > self.level:\n",
    "            for i in range(self.level + 1, new_level + 1):\n",
    "                update[i] = self.head\n",
    "            self.level = new_level\n",
    "        new_node = SkipNode(key, value, new_level)\n",
    "        for i in range(new_level + 1):\n",
    "            new_node.forward[i] = update[i].forward[i]\n",
    "            update[i].forward[i] = new_node\n",
    "    \n",
    "    def delete(self, key: Any):\n",
    "        update = [None] * (self.max_level + 1)\n",
    "        current = self.head\n",
    "        for i in range(self.level, -1, -1):\n",
    "            while current.forward[i] and self._compare_keys(current.forward[i].key, key) < 0:\n",
    "                current = current.forward[i]\n",
    "            update[i] = current\n",
    "        current = current.forward[0]\n",
    "        if current and self._compare_keys(current.key, key) == 0:\n",
    "            for i in range(self.level + 1):\n",
    "                if update[i].forward[i] != current:\n",
    "                    break\n",
    "                update[i].forward[i] = current.forward[i]\n",
    "            while self.level > 0 and self.head.forward[self.level] is None:\n",
    "                self.level -= 1\n",
    "    \n",
    "    def _compare_keys(self, key1: Any, key2: Any) -> int:\n",
    "        if key1 is None and key2 is None:\n",
    "            return 0\n",
    "        elif key1 is None:\n",
    "            return -1\n",
    "        elif key2 is None:\n",
    "            return 1\n",
    "        else:\n",
    "            return (key1 > key2) - (key1 < key2)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        current = self.head.forward[0]\n",
    "        while current:\n",
    "            yield (current.key, current.value)\n",
    "            current = current.forward[0]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        elements = list(self)\n",
    "        return f\"SkipList({elements})\"\n",
    "    \n",
    "def skip_list_join(left_data: List[Dict], right_data: List[Dict], \n",
    "                   left_key: str, right_key: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform an inner join using a skip list to index the right table\n",
    "    \"\"\"\n",
    "    # Build a skip list index on the right table\n",
    "    skip_list = SkipList()\n",
    "    start_build = time.time()\n",
    "    \n",
    "    for record in right_data:\n",
    "        key = record[right_key]\n",
    "        skip_list.insert(key, record)\n",
    "    \n",
    "    build_time = time.time() - start_build\n",
    "    print(f\"Skip list build time: {build_time:.6f} seconds\")\n",
    "    \n",
    "    # Perform the join by searching the skip list for each record in the left table\n",
    "    start_join = time.time()\n",
    "    result = []\n",
    "    \n",
    "    for left_record in left_data:\n",
    "        left_val = left_record[left_key]\n",
    "        right_records = skip_list.search(left_val)\n",
    "        \n",
    "        if right_records:\n",
    "            # Handle case where we have multiple matches\n",
    "            if isinstance(right_records, list):\n",
    "                for right_record in right_records:\n",
    "                    joined_record = {**left_record, **right_record}\n",
    "                    result.append(joined_record)\n",
    "            else:\n",
    "                joined_record = {**left_record, **right_records}\n",
    "                result.append(joined_record)\n",
    "    \n",
    "    join_time = time.time() - start_join\n",
    "    print(f\"Skip list join time: {join_time:.6f} seconds\")\n",
    "    print(f\"Total skip list join time: {build_time + join_time:.6f} seconds\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def hash_join(left_data: List[Dict], right_data: List[Dict], \n",
    "              left_key: str, right_key: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform an inner join using a hash table to index the right table\n",
    "    \"\"\"\n",
    "    # Build a hash table index on the right table\n",
    "    start_build = time.time()\n",
    "    hash_table = {}\n",
    "    \n",
    "    for record in right_data:\n",
    "        key = record[right_key]\n",
    "        if key in hash_table:\n",
    "            hash_table[key].append(record)\n",
    "        else:\n",
    "            hash_table[key] = [record]\n",
    "    \n",
    "    build_time = time.time() - start_build\n",
    "    print(f\"Hash table build time: {build_time:.6f} seconds\")\n",
    "    \n",
    "    # Perform the join by searching the hash table for each record in the left table\n",
    "    start_join = time.time()\n",
    "    result = []\n",
    "    \n",
    "    for left_record in left_data:\n",
    "        left_val = left_record[left_key]\n",
    "        if left_val in hash_table:\n",
    "            for right_record in hash_table[left_val]:\n",
    "                joined_record = {**left_record, **right_record}\n",
    "                result.append(joined_record)\n",
    "    \n",
    "    join_time = time.time() - start_join\n",
    "    print(f\"Hash join time: {join_time:.6f} seconds\")\n",
    "    print(f\"Total hash join time: {build_time + join_time:.6f} seconds\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def pandas_join(left_data: List[Dict], right_data: List[Dict], \n",
    "                left_key: str, right_key: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform an inner join using pandas\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert lists of dictionaries to pandas DataFrames\n",
    "    left_df = pd.DataFrame(left_data)\n",
    "    right_df = pd.DataFrame(right_data)\n",
    "    \n",
    "    # Perform the join\n",
    "    result_df = pd.merge(left_df, right_df, left_on=left_key, right_on=right_key)\n",
    "    \n",
    "    # Convert the result back to a list of dictionaries\n",
    "    result = result_df.to_dict('records')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Pandas join time: {end_time - start_time:.6f} seconds\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def nested_loop_join(left_data: List[Dict], right_data: List[Dict], \n",
    "                     left_key: str, right_key: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform a simple nested loop join\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    result = []\n",
    "    \n",
    "    for left_record in left_data:\n",
    "        for right_record in right_data:\n",
    "            if left_record[left_key] == right_record[right_key]:\n",
    "                joined_record = {**left_record, **right_record}\n",
    "                result.append(joined_record)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Nested loop join time: {end_time - start_time:.6f} seconds\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_test_data(size_left: int, size_right: int, \n",
    "                       key_range: int, skewed: bool = False, \n",
    "                       string_keys: bool = False, null_ratio: float = 0.0,\n",
    "                       seed: int = 42) -> Tuple[List[Dict], List[Dict]]:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    left_data = []\n",
    "    right_data = []\n",
    "    \n",
    "    for i in range(size_left):\n",
    "        if string_keys:\n",
    "            key = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n",
    "        else:\n",
    "            key = random.randint(1, key_range) if not skewed or random.random() >= 0.9 else random.randint(1, key_range // 10)\n",
    "        \n",
    "        if random.random() < null_ratio:\n",
    "            key = None\n",
    "        \n",
    "        record = {\n",
    "            'id': i,\n",
    "            'join_key': key,\n",
    "            'value_left': f\"left_value_{i}\",\n",
    "            'extra_attr': random.random()\n",
    "        }\n",
    "        left_data.append(record)\n",
    "    \n",
    "    for i in range(size_right):\n",
    "        if string_keys:\n",
    "            key = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n",
    "        else:\n",
    "            key = random.randint(1, key_range) if not skewed or random.random() >= 0.9 else random.randint(1, key_range // 10)\n",
    "        \n",
    "        if random.random() < null_ratio:\n",
    "            key = None\n",
    "        \n",
    "        record = {\n",
    "            'id': i,\n",
    "            'join_key': key,\n",
    "            'value_right': f\"right_value_{i}\",\n",
    "            'extra_attr': random.random()\n",
    "        }\n",
    "        right_data.append(record)\n",
    "    \n",
    "    return left_data, right_data\n",
    "\n",
    "    \n",
    "def test_joins():\n",
    "    \"\"\"\n",
    "    Test different join algorithms with various data sizes and distributions\n",
    "    \"\"\"\n",
    "    sizes = [\n",
    "        (\"Large\", 100000, 100000, 50000),\n",
    "    ]\n",
    "    \n",
    "    for size_name, left_size, right_size, key_range in sizes:\n",
    "        print(f\"\\n=== {size_name} Dataset Test (Uniform Distribution) ===\")\n",
    "        left_data, right_data = generate_test_data(left_size, right_size, key_range)\n",
    "        \n",
    "        skip_result = skip_list_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        hash_result = hash_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        pandas_result = pandas_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        \n",
    "        print(f\"Skip list join result size: {len(skip_result)}\")\n",
    "        print(f\"Hash join result size: {len(hash_result)}\")\n",
    "        print(f\"Pandas join result size: {len(pandas_result)}\")\n",
    "        \n",
    "        if size_name == \"Small\":\n",
    "            nested_result = nested_loop_join(left_data, right_data, 'join_key', 'join_key')\n",
    "            print(f\"Nested loop join result size: {len(nested_result)}\")\n",
    "        \n",
    "        print(f\"\\n=== {size_name} Dataset Test (Skewed Distribution) ===\")\n",
    "        left_data, right_data = generate_test_data(left_size, right_size, key_range, skewed=True)\n",
    "        \n",
    "        skip_result = skip_list_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        hash_result = hash_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        pandas_result = pandas_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        \n",
    "        print(f\"Skip list join result size: {len(skip_result)}\")\n",
    "        print(f\"Hash join result size: {len(hash_result)}\")\n",
    "        print(f\"Pandas join result size: {len(pandas_result)}\")\n",
    "        \n",
    "        if size_name == \"Small\":\n",
    "            nested_result = nested_loop_join(left_data, right_data, 'join_key', 'join_key')\n",
    "            print(f\"Nested loop join result size: {len(nested_result)}\")\n",
    "        \n",
    "        print(f\"\\n=== {size_name} Dataset Test (String Keys) ===\")\n",
    "        left_data, right_data = generate_test_data(left_size, right_size, key_range, string_keys=True)\n",
    "        \n",
    "        skip_result = skip_list_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        hash_result = hash_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        pandas_result = pandas_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        \n",
    "        print(f\"Skip list join result size: {len(skip_result)}\")\n",
    "        print(f\"Hash join result size: {len(hash_result)}\")\n",
    "        print(f\"Pandas join result size: {len(pandas_result)}\")\n",
    "        \n",
    "        if size_name == \"Small\":\n",
    "            nested_result = nested_loop_join(left_data, right_data, 'join_key', 'join_key')\n",
    "            print(f\"Nested loop join result size: {len(nested_result)}\")\n",
    "        \n",
    "        print(f\"\\n=== {size_name} Dataset Test (Null Values) ===\")\n",
    "        left_data, right_data = generate_test_data(left_size, right_size, key_range, null_ratio=0.1)\n",
    "        \n",
    "        skip_result = skip_list_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        hash_result = hash_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        pandas_result = pandas_join(left_data, right_data, 'join_key', 'join_key')\n",
    "        \n",
    "        print(f\"Skip list join result size: {len(skip_result)}\")\n",
    "        print(f\"Hash join result size: {len(hash_result)}\")\n",
    "        print(f\"Pandas join result size: {len(pandas_result)}\")\n",
    "        \n",
    "        if size_name == \"Small\":\n",
    "            nested_result = nested_loop_join(left_data, right_data, 'join_key', 'join_key')\n",
    "            print(f\"Nested loop join result size: {len(nested_result)}\")\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    test_joins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfcb5aa-3f1b-4aba-b6aa-f28d626225b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Data Science)",
   "language": "python",
   "name": "py311ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
